# Wrangle yo' data

## Announcements

### Comments on assignments

- Great job overall!

__Worksheet__: You can find the worksheet template for today
[here](https://raw.githubusercontent.com/USF-Psych-DataSci/Classroom/master/tutorials/s04_data-wrangling-exercise.Rmd).


## Today's Topics

Today we'll get started with learning to "wrangle" dataâ€”that is, to subset it, 
rearrange it, transform it, summarize it, and otherwise make it ready for 
analysis. We are going to be working with the [`dplyr`](https://dplyr.tidyverse.org/) 
package. Specifically, we're going to consider three lessons today:

- Intro to `dplyr` syntax
- The `%>%` pipe and the `dplyr` advantage
- `filter`; relational/comparison and logical operators in R

- Specific `dplyr` functions we will cover
  - `select()`
  - `arrange()`
  - `filter()`
  - `mutate()`
  - `summarize()`
  - `group_by()`
      - grouped `mutate()`
      - grouped `summarize()`
  - `across()`
  - `rowwise()`
  - `recode()`

## Resources

STAT 545 chapters:

  - [stat545: dplyr-intro](http://stat545.com/block009_dplyr-intro.html)
  - [stat545: dplyr-single](https://stat545.com/dplyr-single.html)

More detail can be found in the [r4ds: transform](http://r4ds.had.co.nz/transform.html) chapter.

Here are some supplementary resources:

- A similar resource to the r4ds one above is the [intro to dplyr vignette](https://cran.r-project.org/web/packages/dplyr/vignettes/dplyr.html).
- Want to read more about piping? See [r4ds: pipes](http://r4ds.had.co.nz/pipes.html).

Some advanced topics you might find useful:

- For window functions and how dplyr handles them, see the [window-functions](https://cran.r-project.org/web/packages/dplyr/vignettes/window-functions.html) vignette for the `dplyr` package. 
- For time series data, see the [tsibble demo](https://tsibble.tidyverts.org/)


## Intro to `dplyr` syntax

### Learning Objectives

Here are the concepts we'll be exploring in this lesson:

- tidyverse
- `dplyr` functions:
    - select
    - arrange
- piping

By the end of this lesson, students are expected to be able to:

- subset and rearrange data with `dplyr`
- use piping (`%>%`) when implementing function chains

### Preamble

Let's talk about:

- The history of `dplyr`: `plyr`
  - Don't use both in one script!
  - My recommendation, don't use `plyr` at all at this point.
- tibbles are a special type of data frame
- The [tidyverse](https://www.tidyverse.org/)
- Package functions and masking
  - Load the `tidyverse` package: `library(tidyverse)`

### Demonstration

Let's get started with the exercise:

1. Open the `s04_data-wrangling-exercise.Rmd` worksheet in RStudio.
2. Follow along in the `.Rmd` file until the *Back to Guide* section.


## The `dplyr` advantage

### Learning Objectives

By the end of this lesson, you will:

- Have a sense of why `dplyr` is advantageous compared to the "base R" way with respect to good coding practice.

Why?

- Having this in the back of your mind will help you identify qualities of and produce a readable analysis.

### Compare base R to `dplyr`

__Self-documenting code__. 

This is where the tidyverse shines.

Example of `dplyr` vs base R:

```
gapminder[gapminder$country == "Cambodia", c("year", "lifeExp")]
```

vs.

```
gapminder %>%
  filter(country == "Cambodia") %>%
  select(year, lifeExp)
```

![Morning Routine Pipie](https://raw.githubusercontent.com/USF-Psych-DataSci/Classroom/master/img/pipe_routine.jpg)

### The workflow:

1. Wrangle your data with `dplyr` first
2. Pipe `%>%` your data into a plot/analysis

### Basic principles:

1. Do one thing at a time
  - Transform variables OR select variables OR filter cases
2. Chain multiple operations together using the pipe `%>%` 
3. Use readable object and variable names
4. Subset a dataset (i.e., select variables) by **name**, not by "magic numbers"
5. _Note that you need to use the assignment operator `<-` to store changes!_

### Tangent: Base R workflow

- We are jumping right into the tidyverse way of doing things in R, instead of the base R way of doing things. Our first week was about "just enough" base R to get you started. If you feel that you want more practice here, take a look at [the R intro stat videos by MarinStatsLectures](https://www.youtube.com/playlist?list=PLqzoL9-eJTNARFXxgwbqGo56NtbJnB37A).


## Relational/Comparison and Logical Operators in R

### Learning Objectives

Here are the concepts we'll be exploring in this lesson:

- Relational/comparison operators
- Logical operators
- `dplyr` functions:
    - filter
    - mutate

By the end of this lesson, you will be able to:

- Predict the output of R code containing the above operators.
- Explain the difference between `&`/`&&` and `|`/`||`, and name a situation 
  where one should be used over the other.
- Subsetting and transforming data using filter and mutate

### R Operators

**Arithmetic** operators allow us to carry out mathematical operations:

| Operator | Description |
|------|:---------|
| + | Add |
| - | Subtract |
| * | Multiply |
| / | Divide |
| ^ | Exponent |
| %/% | Integer division |
| %% | Modulus (remainder from integer division) |

**Relational** operators allow us to compare values:

| Operator | Description |
|------|:---------|
| < | Less than |
| > | Greater than |
| <= | Less than or equal to |
| >= | Greater than or equal to |
| == | Equal to |
| != | Not equal to |

* Arithmetic and relational operators work on vectors.

There is another very useful relational function, `%in%`:

```{r}
c(1, 2, 3, 4, 5) %in% c(1, 2)
```

**Logical** operators allow us to carry out boolean operations:

| Operator | Description |
|---|:---|
| ! | Not |
| \| | Or (element_wise) |
| & | And (element-wise) |
| \|\| | Or |
| && | And |

* The difference between `|` and `||` is that `||` evaluates only the first 
element of the two vectors, whereas `|` evaluates element-wise. 

### Demonstration

Continue along with the worksheet until **Back to Guide Again**.


## Picking up where we left off

__Worksheet__: You can find the worksheet template for today
[here](https://raw.githubusercontent.com/USF-Psych-DataSci/Classroom/master/tutorials/s05_data-wrangling-exercise_part-2.Rmd).

## `summarize()`

Like `mutate()`, the `summarize()` function also creates new columns, but the 
calculations that make the new columns must reduce down to a single number. 

For example, let's compute the mean and standard deviation of life expectancy 
in the gapminder data set:

```{r}
gapminder %>% 
  summarize(mu    = mean(lifeExp),
            sigma = sd(lifeExp))
```

Notice that all other columns were dropped. This is necessary, because there's 
no obvious way to compress the other columns down to a single row. This is 
unlike `mutate()`, which keeps all columns, and more like `transmute()`, which 
drops all other columns.

As it is, this is hardly useful. (Though it is useful for creating Table 1 in 
your papers.) But summarizing is more useful in the context of _grouping_, 
coming up next.


## `group_by()`

The true power of `dplyr` lies in its ability to group a tibble, with the 
`group_by()` function. As usual, this function takes in a tibble and returns a 
(grouped) tibble. 

Let's group the gapminder dataset by continent and year:

```{r}
gapminder %>% 
  group_by(continent, year)
```

The only thing different from a regular tibble is the indication of grouping 
variables above the tibble. This means that the tibble is recognized as having 
"chunks" defined by unique combinations of continent and year:

- Asia in 1952 is one chunk.
- Asia in 1957 is another chunk.
- Europe in 1952 is another chunk.
- etc...

Notice that the data frame isn't _rearranged_ by chunk! The grouping is something
stored internally about the grouped tibble.

Now that the tibble is grouped, operations that you do on a grouped tibble 
_will be done independently within each chunk_, as if no other chunks exist. 

You can also create new variables and group by that variable simultaneously. 
Try splitting life expectancy by "small" and "large" using 60 as a threshold:

```{r}
gapminder %>% 
  group_by(smallLifeExp = lifeExp < 60)
```

### Grouped `summarize()`

Want to compute the mean and standard deviation for each year for every 
continent? No problem:

```{r}
gapminder %>% 
  group_by(continent, year) %>% 
  summarize(mu    = mean(lifeExp),
            sigma = sd(lifeExp))
```

Notice:

- The grouping variables are kept in the tibble, because their values are unique 
  within each chunk (by definition of the chunk!)
- With each call to `summarize()`, the grouping variables are "peeled back" from 
  last grouping variable to first.

This means the above tibble is now only grouped by continent. What happens when 
we reverse the grouping?

```{r}
gapminder %>% 
  group_by(year, continent) %>%    # Different order
  summarize(mu    = mean(lifeExp),
            sigma = sd(lifeExp))
```

The grouping columns are switched, and now the tibble is grouped by year instead 
of continent. 

`dplyr` has a bunch of convenience functions that help us write code more 
eloquently. We could use `group_by()` and `summarize()` with `length()` to find 
the number of entries each country has:

```{r}
gapminder %>% 
  group_by(country) %>% 
  transmute(n = length(country))
```

Or, we can use the more elegant `dplyr::n()` to count the number of rows in each 
group:

```{r}
gapminder %>% 
  group_by(country) %>% 
  summarize(n = n())
```

Or better yet, if this is all we want, just use `dplyr::count()`:

```{r}
gapminder %>% 
  count(country)
```

### Grouped `mutate()`

Want to get the increase in GDP per capita for each country? No problem:

```{r}
gap_inc <- gapminder %>% 
  arrange(year) %>% 
  group_by(country) %>%
  mutate(gdpPercap_inc = gdpPercap - lag(gdpPercap))
print(gap_inc)
```

The tibble is still grouped by country.

Drop the `NA`s with another convenience function, this time supplied by the 
`tidyr` package (another tidyverse package that we'll see soon):

```{r}
gap_inc %>% 
  tidyr::drop_na()
```

You can specify specific columns to drop `NA`s from in the `drop_na()` function.

## Function types

We've seen cases of transforming variables using `mutate()` and `summarize()`, 
both with and without `group_by()`. How can you know what combination to use? 
Here's a summary based on one of three types of functions.


| Function type | Explanation | Examples | In `dplyr` |
|------|-----|----|----|
| Vectorized functions | These take a *vector*, and operate on each component independently to return a vector of the same length. In other words, they work element-wise. | `cos()`, `sin()`, `log()`, `exp()`, `round()` | `mutate()` |
| Aggregate functions | These take a vector, and return a vector of length 1 | `mean()`, `sd()`, `length()` | `summarize()`, esp with `group_by()`. |
| Window Functions | these take a vector, and return a vector of the same length that depends on the vector as a whole. | `lag()`, `rank()`, `cumsum()` | `mutate()`, esp with `group_by()` |


## `recode()`

`recode()` is useful for recoding categorical variables.

Unlike most of the other function in `dplyr`, `recode()` is backwards in it's syntax:

```
recode(.x, old = new)
```
Lets take a look at recoding different variables using the `psychTools::bfi` dataset:

In the dataset, our `gender` variable has values 1 and 2.

This is a little vague since we don't know what 1 or 2 is in respect to gender.

```{r}
dat_bfi <- psychTools::bfi %>% 
  rownames_to_column(var = ".id")

dat_bfi %>%
  mutate(
    gender = recode(gender, "1" = "man", "2" = "woman")
  ) %>%
  select(.id, gender, education)
```

*Note that for numeric values, you need to wrap them in "quotes" or `backticks`; however, that's not necessary for character values*

We can also specify a `.default` value within our `recode()`.

For example, say we want to have just "HS or less" versus "more than HS"

```{r}
dat_bfi %>%
  mutate(
    education = recode(education, "1" = "HS", "2" = "HS", .default = "More than HS")
  ) %>%
  select(.id, gender, education)
```

Another neat feature of the `recode()` function is the `.missing` value.

If we would rather convert NA values to something more explicit we can specify that in the `.missing` argument.

```{r}
dat_bfi %>%
  mutate(
    education = recode(education, "1" = "HS", "2" = "HS", .default = "More than HS", .missing = "(Unknown)")
  ) %>%
  select(.id, gender, education)
```

Or we can use `tidyr::replace_na()` 

```{r}
dat_bfi %>%
  mutate(
    education = replace_na(education, replace = "(Unknown)")
  ) %>%
  select(.id, gender, education)
```


## `across()`

The `across` function allows us to apply transformations across multiple columns

Say we wanted to look at the mean of each agreeable variable between gender groups:

```{r}
dat_bfi %>%
  group_by(gender) %>%
  summarize(
    across(
      A1:A5,
      ~ mean(.x, na.rm = T)
    )
  )
```

What if we wanted to include the standard deviation as well? We can pass a `list` of functions into `across()`

```{r}
dat_bfi %>%
  group_by(gender) %>%
  summarize(
    across(
      A1:A5,
      list(
     mean = ~ mean(.x, na.rm = T),
     sd = ~ sd(.x, na.rm = T)
      )
    )
  )
```

### Complex `recoding` & `across()`

Now sometimes with our scales we may encounter variables that are reverse scored.

```{r}
dat_bfi %>%
  mutate(A1r = recode(A1, "6" = 1, "5" = 2, "4" = 3, "3" = 4, "2" = 5, "1" = 6)) %>%
  select(A1, A1r)

# or

dat_bfi %>%
  mutate(A1r = 7 - A1) %>%
  select(A1, A1r)
```

However, we can implement some more complex code that will reverse `recode()` in one fell swoop!

We start with either specifying our columns that need reverse coding or get it from a data dictionary:

```{r}
reversed <- c("A1", "C4", "C5", "E1", "E2", "O2", "O5")

# or

dict <- psychTools::bfi.dictionary %>%
  as_tibble(rownames = "item")

reversed <- dict %>%
  filter(Keying == -1) %>%
  pull(item)
```

Putting it all together: 

```{r}
dat_bfi %>%
  mutate(
    across(all_of(reversed),
      ~ recode(.x, "6" = 1, "5" = 2, "4" = 3, "3" = 4, "2" = 5, "1" = 6),
      .names = "{.col}r"
    )
  )
```

*Note that we can use the `.names` argument to aid in the naming of our new columns*

## `rowwise()`

The `rowwise()` function lets us look at the data frame one row-at-a-time and apply functions as such.

Looking back at `dat_bfi`, say we wanted to get the total score of our scales per response:

```{r}
dat_bfi %>%
  rowwise() %>% 
  summarise(
    .id = .id,
    A_sum = sum(c_across(A1:A5)),
    C_sum = sum(c_across(C1:C5)),
    E_sum = sum(c_across(E1:E5)),
    N_sum = sum(c_across(N1:N5)),
    O_sum = sum(c_across(O1:O5))
  )
```

## `dplyr` Exercises

Let's go to the worksheet and work on the exercises.
